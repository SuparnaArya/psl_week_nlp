{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be16b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fd3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "readRDS = robjects.r['readRDS']\n",
    "df = readRDS('F:/IASD - PSL/PSL Week/NLP_lecture_PSLWeek-main/Data/UD.rds')\n",
    "df = pandas2ri.rpy2py_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0950983e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'ai accouché en février 2019 et ma fille n'est pas encore inscrite à la CAF.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096ab784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07584fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "972858c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization of each document\n",
    "tokenized_doc = []\n",
    "for d in df['sentence'].values:\n",
    "    tokenized_doc.append(word_tokenize(d.lower()))\n",
    "#tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6059712",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_doc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f225ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8b1df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english') + stopwords.words('french')\n",
    "#stop_words=[word.decode('utf-8') for word in (stopwords.words('french'))]\n",
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c61ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_sentence=[]\n",
    "filtered_tokens=[]\n",
    "for doc in tokenized_doc:\n",
    "    filtered_sentence=[w for w in doc if not (w in stop_words or w==\".\")]\n",
    "    filtered_tokens.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "254d7020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"j'ai\",\n",
       " 'accouché',\n",
       " 'février',\n",
       " '2019',\n",
       " 'fille',\n",
       " \"n'est\",\n",
       " 'encore',\n",
       " 'inscrite',\n",
       " 'caf']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=filtered_tokens[1]\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75671b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenized document into gensim formated tagged data\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(filtered_tokens)]\n",
    "tagged_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346499c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size=100, dbow_words= 1, dm=0, window=5, seed=1337, min_count=5, workers=4,alpha=0.025, min_alpha=0.025)\n",
    "model.build_vocab(tagged_data)\n",
    "for epoch in range(10):\n",
    "    print(\"epoch \"+str(epoch))\n",
    "    model.train(tagged_data,total_examples=model.corpus_count, epochs=1)\n",
    "    model.save('F:\\IASD - PSL\\PSL Week\\Hackathon\\doc2vec.model')\n",
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fba89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec.load('F:\\IASD - PSL\\PSL Week\\Hackathon\\doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b005c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_situations=['mariage','pacs','concubinage','marier','pacser','épouser','civil','famille','divorce','séparation','civil','naissance','enfant','emploi','travail','salarié','embaucher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6095951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mariage': 0.14669679, 'pacs': 0.09909782, 'concubinage': 0.13631359, 'marier': 0.12836395, 'pacser': 0.08915599, 'civil': 0.09938142, 'famille': 0.09757103, 'divorce': 0.14079091, 'séparation': 0.08748729, 'naissance': 0.17686586, 'enfant': 0.12258239, 'emploi': 0.085410446, 'travail': 0.09822284, 'salarié': 0.11018398, 'embaucher': 0.1091334}\n"
     ]
    }
   ],
   "source": [
    "sit={}\n",
    "for i in range(len(life_situations)):\n",
    "    try:\n",
    "        sim=doc2vec_model.wv.similarity(prompt,life_situations[i])\n",
    "        #print(life_situations[i])\n",
    "        #print(max(sim))\n",
    "        x=max(sim)\n",
    "        if x>=0.04:\n",
    "            sit[life_situations[i]]=max(sim)\n",
    "    except:\n",
    "        pass\n",
    "print(sit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "44c8ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_situation(prompt):\n",
    "    tokenized_doc.append(word_tokenize(d.lower()))\n",
    "    filtered_sentence=[w for w in doc if not (w in stop_words or w==\".\")]\n",
    "    sit={}\n",
    "    for i in range(len(life_situations)):\n",
    "        try:\n",
    "            sim=doc2vec_model.wv.similarity(filtered_sentence,life_situations[i])\n",
    "        #print(life_situations[i])\n",
    "        #print(max(sim))\n",
    "            x=max(sim)\n",
    "            if x>=0.4:\n",
    "                sit[life_situations[i]]=max(sim)\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "    if sit=={}:\n",
    "        print('prompt not in life situations')\n",
    "    else:\n",
    "        maximum = max(sit, key=sit.get)\n",
    "        print(maximum, round(sit[maximum],2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fd3ee304",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"J'ai accouché en février 2019 et ma fille n'est pas encore inscrite à la CAF\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "29bbfe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt not in life situations\n"
     ]
    }
   ],
   "source": [
    "predict_situation(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ce8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
